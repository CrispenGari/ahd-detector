{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_AHD_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "Project: `Automatic Humour Detection (AHD)`\n",
        "\n",
        "Programmer: `@crispengari`\n",
        "\n",
        "Date: `2022-04-26`\n",
        "\n",
        "Abstract: _`Automatic Humour Detection (AHD) is a very useful topic in morden technologies. In this notebook we are going to create an Artificial Neural Network model using Deep Learning to detect humour in short texts. AHD are very useful because in model technologies such as virtual assistance and chatbots. They help Artificial Virtual Assistance and Bot to detect wether to take the conversation serious or not`._\n",
        "\n",
        "Research Paper: [`2004.12765`](https://arxiv.org/abs/2004.12765)\n",
        "\n",
        "Keywords: `tensorflow`, `embedding`, `keras`, `pandas`, `CNN`, `dataset`, `accuracy`, `nltk`, `loss`\n",
        "\n",
        "Programming Language: `python`\n",
        "\n",
        "Dataset: [`kaggle`](https://www.kaggle.com/datasets/deepcontractor/200k-short-texts-for-humor-detection)\n",
        "___"
      ],
      "metadata": {
        "id": "CjxUtja_yZI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset that we are going to use is based on the `3` files which are stored in the google drive which are:\n",
        "\n",
        "1. train.csv\n",
        "2. val.csv\n",
        "3. test.csv\n",
        "\n",
        "We are going to use `torchtext` and pytorch to create this model. We are going to create a `CNN` model that will perform a binary classification using tensorflow and keras.\n",
        "\n",
        "\n",
        "### Mounting the Drive\n",
        "We are mounting the drive because we are going to load the files from our google drive. In the following code cell we are going to mount the drive as follows:"
      ],
      "metadata": {
        "id": "71TdrUik0pYZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEoiLdwWyS1b",
        "outputId": "5f6254d3-cb75-4210-fa6f-26a283dc0d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports\n",
        "In the following code cell, we are going to import basic packages that we are going to use through out this notebook."
      ],
      "metadata": {
        "id": "p_WZDNWi2h_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "from matplotlib import pyplot as plt\n",
        "from prettytable import PrettyTable\n",
        "from collections import Counter\n",
        "from tensorflow import keras\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "tf.__version__, keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QXC0FA_2rce",
        "outputId": "92822409-d6fa-4bdf-9e3b-134f73541b12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.8.0', '2.8.0')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seeds\n",
        "Setting the seed helps us for reproducibility."
      ],
      "metadata": {
        "id": "qVey4DKTPq98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "9lplp93dP6tG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device\n",
        "We must make use of `gpu` accellaration if possible"
      ],
      "metadata": {
        "id": "EZqnPssXPXJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "else:\n",
        "  print(\"No GPU's\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_mJ2HQ8Pdnv",
        "outputId": "316aa466-6896-459f-f95f-737e030c7601"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paths to data\n",
        "In the following code cells we are going to define the path where our `csv` files are located."
      ],
      "metadata": {
        "id": "8QcJwfwX2N5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splits_folder = \"/content/drive/My Drive/NLP Data/Automatic Humor Detection/splits\"\n",
        "assert os.path.exists(splits_folder) == True\n"
      ],
      "metadata": {
        "id": "s0sEoiYmyYfs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the data\n",
        "\n",
        "We are going to read the data from our 3 files as dataframes."
      ],
      "metadata": {
        "id": "MGFJjtpRh-A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(splits_folder, 'train.csv'))\n",
        "test_df = pd.read_csv(os.path.join(splits_folder, 'test.csv'))\n",
        "val_df = pd.read_csv(os.path.join(splits_folder, 'val.csv'))"
      ],
      "metadata": {
        "id": "EjoEe5GoclhU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Features and Labels\n",
        "Next we are going to extract features and labels fron the from our dataframes for all the three sets."
      ],
      "metadata": {
        "id": "Ks-ESfGQiHDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_texts = train_df.text.values\n",
        "train_labels = train_df.label.values\n",
        "\n",
        "# test\n",
        "test_texts = test_df.text.values\n",
        "test_labels = test_df.label.values\n",
        "\n",
        "# val\n",
        "val_texts = val_df.text.values\n",
        "val_labels = val_df.label.values"
      ],
      "metadata": {
        "id": "8awsFkIKXFA_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzsIwzz_t5Qm",
        "outputId": "05195693-eb97-47c9-e2dd-0e63075b00cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['not-humour', 'humour'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label encoding\n",
        "\n",
        "As we can see our labels are strings and we want to convert them to `numbers` so we are going to make use of the `sklearn` LabelEncoder class to encode our labels to numeric."
      ],
      "metadata": {
        "id": "ir2LFfUut_Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV1c9ID0t8fE",
        "outputId": "4f82be8d-c3a6-4d9b-c829-b8e1b4748e97"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming Labels\n",
        "To transform the labels we need to call the `encoder.transform()` on our three sets of labels."
      ],
      "metadata": {
        "id": "HtldXe9Luo6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = encoder.transform(train_labels)\n",
        "test_labels = encoder.transform(test_labels)\n",
        "val_label = encoder.transform(val_labels)"
      ],
      "metadata": {
        "id": "tKvHgJX5uhNh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY6sRk1xu9cT",
        "outputId": "2278e3e8-b71e-414e-b331-da085570a0af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing the text\n",
        "We are going to create a `vocabulary` based on our train data using the `Counter` from the `collections` module in the following code cell."
      ],
      "metadata": {
        "id": "lzUnchjFvEbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "Kulj2XG9v0Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28a4eb7-27a9-4a44-beae-76cd50d901c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter()\n",
        "\n",
        "for sent in train_texts:\n",
        "  counter.update(word_tokenize(sent))"
      ],
      "metadata": {
        "id": "-DBDTWUpvfdV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the most common `9` words"
      ],
      "metadata": {
        "id": "y5j6cx5vwAfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter.most_common(9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9a4wy8zwEUl",
        "outputId": "4eeadba7-4478-4983-ef74-4c730299f0fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 67724),\n",
              " ('the', 67301),\n",
              " ('a', 66128),\n",
              " ('?', 54788),\n",
              " ('to', 48363),\n",
              " (',', 37160),\n",
              " (\"'s\", 35868),\n",
              " ('you', 34041),\n",
              " ('of', 29679)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary size"
      ],
      "metadata": {
        "id": "NTTJhXW7wKcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(counter)"
      ],
      "metadata": {
        "id": "xdeUILzKwfhv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN3qzXE-wwUf",
        "outputId": "1f4417f6-cded-47eb-eedc-3936008078b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86227"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating word vectors.\n"
      ],
      "metadata": {
        "id": "l53JJI7Qwy8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "    num_words = vocab_size\n",
        ")\n",
        "tokenizer.fit_on_texts(train_texts)"
      ],
      "metadata": {
        "id": "hTSwSKVCxHY0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_indices = tokenizer.word_index\n",
        "word_indices_reversed = dict([(v, k) for (k, v) in word_indices.items()])"
      ],
      "metadata": {
        "id": "F3h7KFZfxhcc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP5lsDR-xp8c",
        "outputId": "1195d2ea-45a1-43c8-f15e-8da43d54c6fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73528"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions\n",
        "\n",
        "1. `sequence_to_text`\n",
        "\n",
        "This helper function will convert a sequence of integers to a sequence of text.\n",
        "\n",
        "2. `text_to_sequence`\n",
        "\n",
        "This helper function will convert the sequence of text to sequence of integers.\n"
      ],
      "metadata": {
        "id": "CqsbYaz4yCWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_to_text(sequences):\n",
        "    return \" \".join(word_indices_reversed[i] for i in sequences)\n",
        "    \n",
        "def text_to_sequence(sent):\n",
        "  words = word_tokenize(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(word_indices[word])\n",
        "    except:\n",
        "      sequences.append(0)\n",
        "  return sequences"
      ],
      "metadata": {
        "id": "fSgubVJ4ygok"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading pretrainned vectors\n",
        "We are going to load the `Glove.6B.100d` word vectors that was uploaded in the google drive as a `txt` file.\n"
      ],
      "metadata": {
        "id": "f5e9bNu4y79q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_path = \"/content/drive/MyDrive/NLP Data/glove.6B/glove.6B.100d.txt\"\n",
        "\n",
        "assert os.path.exists(embedding_path) == True, \"The path does not exists\""
      ],
      "metadata": {
        "id": "7HDDVpCmzXLx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dictionary = dict()\n",
        "with open(embedding_path, encoding='utf8') as glove_file:\n",
        "  for line in glove_file:\n",
        "    records = line.split()\n",
        "    word  = records[0]\n",
        "    vectors = np.asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vectors"
      ],
      "metadata": {
        "id": "0HBalW_3zl5I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Creating embedding matrix that suits our data."
      ],
      "metadata": {
        "id": "UGnGIndmztkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  vector = embeddings_dictionary.get(word)\n",
        "  if vector is not None:\n",
        "    try:\n",
        "      embedding_matrix[index] = vector\n",
        "    except:\n",
        "      pass"
      ],
      "metadata": {
        "id": "77pSK48Sz0km"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating sequences\n",
        "\n",
        "In the following code cell we are going to create the sequences on our 3 sets."
      ],
      "metadata": {
        "id": "ucnaqwKoz7pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequence_tokens = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequence_tokens = tokenizer.texts_to_sequences(test_texts)\n",
        "val_sequence_tokens = tokenizer.texts_to_sequences(val_texts)"
      ],
      "metadata": {
        "id": "bmV4uMms0JTi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_to_text(train_sequence_tokens[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "976-2wtM0Pj-",
        "outputId": "73bfc9a4-bb3a-46a9-d611-1ddec52754df"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the richest black man in nyc has got to be duane reade'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_to_text(test_sequence_tokens[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q4zaMSVa1k9G",
        "outputId": "38db05f2-202e-4a11-8ee4-c1f1afcd021e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mary alice glam4good was inspired by oprah video'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_to_text(val_sequence_tokens[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9NqzlC_81po0",
        "outputId": "cdfb2698-25cc-4717-a1a8-2dce5df14246"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"darth vader showed up to luke's party uninvited talk about a foe pa\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding the `sequences`\n",
        "Next we want to pad the sequences to have the same length as we can see that these sentences contains different lengths, so we have to pad the small sentences with `0` and trancate the large sentences."
      ],
      "metadata": {
        "id": "TVu29o7w0WCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 100\n",
        "train_tokens_sequence_padded = keras.preprocessing.sequence.pad_sequences(\n",
        "                                       train_sequence_tokens,\n",
        "                                       maxlen=max_words,\n",
        "                                       padding=\"post\", \n",
        "                                       truncating=\"post\"\n",
        "                                       )\n",
        "test_tokens_sequence_padded = keras.preprocessing.sequence.pad_sequences(\n",
        "                                       test_sequence_tokens,\n",
        "                                       maxlen=max_words,\n",
        "                                       padding=\"post\", \n",
        "                                       truncating=\"post\"\n",
        "                                       )\n",
        "val_tokens_sequence_padded = keras.preprocessing.sequence.pad_sequences(\n",
        "                                       val_sequence_tokens,\n",
        "                                       maxlen=max_words,\n",
        "                                       padding=\"post\", \n",
        "                                       truncating=\"post\"\n",
        "                                       )"
      ],
      "metadata": {
        "id": "tBkshbS90xQH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "We are going to create a model based on [this notebook](https://github.com/CrispenGari/nlp-tensorflow/blob/main/03_Emotions/01_Emotion_Prediction_From_Text.ipynb). This model is based on a functional API in keras. The model achitecture is a as \n",
        "follows:\n",
        "\n",
        "```\n",
        "                [ Embedding Layer]\n",
        "                        |\n",
        "                        |\n",
        "[ LSTM ] <---- [Bidirectional Layer] ----> [GRU] (forward_layer)\n",
        " (backward_layer)       |\n",
        "                        |\n",
        "        [  Gated Recurrent Unit  (GRU)  ]\n",
        "                        |\n",
        "                        |\n",
        "        [ Long Short Term Memory (LSTM) ]\n",
        "                        |\n",
        "                        |\n",
        "                [ Flatten Layer]\n",
        "                        |\n",
        "                        |\n",
        "                 [Dense Layer 1]\n",
        "                        |\n",
        "                        | \n",
        "                   [ Dropout ]\n",
        "                        |\n",
        "                        |   \n",
        "                 [Dense Layer 2]\n",
        "                        |\n",
        "                        |\n",
        "                 [Dense Layer 3] (output [binary])\n",
        "```"
      ],
      "metadata": {
        "id": "ecSkC668mNnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forward_layer = keras.layers.GRU(128, return_sequences=True, dropout=.25 )\n",
        "backward_layer = keras.layers.LSTM(128, activation='tanh', return_sequences=True,\n",
        "                       go_backwards=True, dropout=.25)\n",
        "\n",
        "input_layer = keras.layers.Input(shape=(100, ), name=\"input_layer\")\n",
        "\n",
        "embedding_layer = keras.layers.Embedding(\n",
        "      vocab_size, \n",
        "      100, \n",
        "      input_length=max_words,\n",
        "      weights=[embedding_matrix], \n",
        "      trainable=True,\n",
        "      name = \"embedding_layer\"\n",
        ")(input_layer)\n",
        "\n",
        "bidirectional_layer = keras.layers.Bidirectional(\n",
        "    forward_layer,\n",
        "    backward_layer = backward_layer,\n",
        "    name= \"bidirectional_layer\"\n",
        ")(embedding_layer)\n",
        "\n",
        "gru_layer = keras.layers.GRU(\n",
        "    512, return_sequences=True,\n",
        "   dropout=.5,\n",
        "    name= \"gru_layer\"\n",
        ")(bidirectional_layer)\n",
        "\n",
        "lstm_layer = keras.layers.LSTM(\n",
        "    512, return_sequences=True,\n",
        "   dropout=.5,\n",
        "    name=\"lstm_layer\"\n",
        ")(gru_layer)\n",
        "flatten_layer = keras.layers.Flatten(name=\"flatten_layer\")(lstm_layer)\n",
        "fc_1 = keras.layers.Dense(64, activation='relu', name=\"dense_1\")(flatten_layer)\n",
        "dropout_layer = keras.layers.Dropout(rate=0.5, name=\"dropout_layer\")(fc_1)\n",
        "fc_2 = keras.layers.Dense(512, activation='relu', name=\"dense_2\")(dropout_layer)\n",
        "output_layer = keras.layers.Dense(1, activation='sigmoid')(fc_2)\n",
        "adh_model = keras.Model(inputs=input_layer, outputs=output_layer, name=\"emotional_model\")\n",
        "adh_model.summary()"
      ],
      "metadata": {
        "id": "6mnl6dNMdFa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba12365-da48-4aa8-db68-e00dbb276bdc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"emotional_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 100, 100)         8622700   \n",
            "                                                                 \n",
            " bidirectional_layer (Bidire  (None, 100, 256)         205568    \n",
            " ctional)                                                        \n",
            "                                                                 \n",
            " gru_layer (GRU)             (None, 100, 512)          1182720   \n",
            "                                                                 \n",
            " lstm_layer (LSTM)           (None, 100, 512)          2099200   \n",
            "                                                                 \n",
            " flatten_layer (Flatten)     (None, 51200)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                3276864   \n",
            "                                                                 \n",
            " dropout_layer (Dropout)     (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               33280     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,420,845\n",
            "Trainable params: 15,420,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model\n",
        "First we need to compile the model and we are going to use the `EarlyStopping` call back so that we stop as soon as the loss start increasing.\n"
      ],
      "metadata": {
        "id": "4Z02fIdUH0xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stoping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        ")\n",
        "\n",
        "adh_model.compile(\n",
        "    loss = keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    optimizer = keras.optimizers.Adam(1e-3, 0.5),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "MrQce1CIIJke"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "adh_model.fit(\n",
        "    train_tokens_sequence_padded,\n",
        "    train_labels,\n",
        "    validation_data=(\n",
        "        val_tokens_sequence_padded,\n",
        "        val_label\n",
        "    ),\n",
        "    epochs = 10,\n",
        "    verbose = 1,\n",
        "    shuffle=True,\n",
        "    batch_size= BATCH_SIZE,\n",
        "    validation_batch_size = BATCH_SIZE,\n",
        "    callbacks = [early_stoping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i83U3HDUImX4",
        "outputId": "146a9859-db07-41a8-c70b-8537ca8e59cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 [==============================] - 378s 260ms/step - loss: 0.1930 - accuracy: 0.9247 - val_loss: 0.1764 - val_accuracy: 0.9375\n",
            "Epoch 2/10\n",
            "1407/1407 [==============================] - 365s 259ms/step - loss: 0.1095 - accuracy: 0.9596 - val_loss: 0.1201 - val_accuracy: 0.9550\n",
            "Epoch 3/10\n",
            "1407/1407 [==============================] - 364s 259ms/step - loss: 0.0776 - accuracy: 0.9715 - val_loss: 0.1077 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 364s 259ms/step - loss: 0.0794 - accuracy: 0.9735 - val_loss: 0.1052 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 364s 259ms/step - loss: 0.0492 - accuracy: 0.9815 - val_loss: 0.1132 - val_accuracy: 0.9590\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 363s 258ms/step - loss: 0.0390 - accuracy: 0.9857 - val_loss: 0.1104 - val_accuracy: 0.9630\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 363s 258ms/step - loss: 0.0327 - accuracy: 0.9881 - val_loss: 0.1318 - val_accuracy: 0.9545\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 363s 258ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.1409 - val_accuracy: 0.9590\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 361s 257ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.1458 - val_accuracy: 0.9585\n",
            "Epoch 9: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1674b260d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model\n",
        "\n",
        "We are going to evaluate the model on the test data."
      ],
      "metadata": {
        "id": "kgnDEhBYJOjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adh_model.evaluate(test_tokens_sequence_padded, test_labels,\n",
        "                       verbose=1, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d22xm35JXf4",
        "outputId": "6b04c044-0eb4-40f7-8528-c25f3501e640"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141/141 [==============================] - 12s 87ms/step - loss: 0.1476 - accuracy: 0.9543\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1475924551486969, 0.9543333053588867]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference\n",
        "In the following code cell we are going to make predictions using our model."
      ],
      "metadata": {
        "id": "gGVzWcf8JsLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_homour(sent: str, model):\n",
        "  classes =[\"HUMOUR\", \"NOT HOMOUR\"]\n",
        "  tokens = text_to_sequence(sent)\n",
        "  padded_tokens = keras.preprocessing.sequence.pad_sequences([tokens],\n",
        "                                maxlen=max_words,\n",
        "                                padding=\"post\", \n",
        "                                truncating=\"post\"\n",
        "                                )\n",
        "  \n",
        "  pred = model.predict(padded_tokens)\n",
        "  pred = tf.squeeze(pred).numpy()\n",
        "  print(pred)\n",
        "  label = 1 if pred >=0.5 else 0\n",
        "  probability = float(round(pred, 3)) if pred >= 0.5 else float(round(1 - pred, 3))\n",
        "\n",
        "  pred_obj ={\n",
        "      \"label\": label,\n",
        "      \"probability\": probability,\n",
        "      \"class\": classes[label]\n",
        "  }\n",
        "  return pred_obj\n",
        "\n",
        "\n",
        "predict_homour(\"The richest black man in nyc has got to be duane reade.\", adh_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7-CgfFXKRnW",
        "outputId": "a04d8a56-d73a-4dbd-e690-31f8ddec459b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06213177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class': 'HUMOUR', 'label': 0, 'probability': 0.938}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "6EqUOXtwNZmq",
        "outputId": "f467a682-67e7-494b-9e1e-4ba47f648c5c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text       label\n",
              "0       38762  10 brands that will disappear in 2014: 24/7 wa...  not-humour\n",
              "1       76883  The richest black man in nyc has got to be dua...      humour\n",
              "2        2018  What do you get if king kong sits on your pian...      humour"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4e5abe7-15c1-4d81-ba30-0f4613c4b2f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38762</td>\n",
              "      <td>10 brands that will disappear in 2014: 24/7 wa...</td>\n",
              "      <td>not-humour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>76883</td>\n",
              "      <td>The richest black man in nyc has got to be dua...</td>\n",
              "      <td>humour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>What do you get if king kong sits on your pian...</td>\n",
              "      <td>humour</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4e5abe7-15c1-4d81-ba30-0f4613c4b2f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4e5abe7-15c1-4d81-ba30-0f4613c4b2f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4e5abe7-15c1-4d81-ba30-0f4613c4b2f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[:3], train_labels[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp9eHSEfL92d",
        "outputId": "6d4e83c8-66c2-4a8e-e96b-52b3286f7596"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['10 brands that will disappear in 2014: 24/7 wall st.',\n",
              "        'The richest black man in nyc has got to be duane reade.',\n",
              "        'What do you get if king kong sits on your piano? a flat note.'],\n",
              "       dtype=object), array([1, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_homour(train_texts[0], adh_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oDVH6MFNKwd",
        "outputId": "99e3a458-cd92-4973-8629-c59006dd5f94"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class': 'NOT HOMOUR', 'label': 1, 'probability': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_homour(train_texts[1], adh_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LZ3D3U5NPlw",
        "outputId": "4e908c7e-7258-4b0e-cb9e-16ee1042f094"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06213177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class': 'HUMOUR', 'label': 0, 'probability': 0.938}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_homour(train_texts[2], adh_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwRTfXlLNRN-",
        "outputId": "e71f302a-35f4-41b3-e723-d801fe9fbd26"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9394454e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class': 'HUMOUR', 'label': 0, 'probability': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and downloading\n",
        "\n",
        "Now we can download the model so that it can be saved as a static file in the following code cell."
      ],
      "metadata": {
        "id": "-7i0CkAi1RCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'adh-tf.h5'\n",
        "adh_model.save(MODEL_NAME)"
      ],
      "metadata": {
        "id": "oya2DX2lLcRz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LgEnezdM1OPh",
        "outputId": "2f1d98b3-9200-4b63-fa10-2fac6b4c1d9d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_436d6d36-629f-4a94-b348-e088f3705948\", \"adh-tf.h5\", 185144616)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and Downloading the vocabulary\n",
        "\n",
        "Next we are going to our vocabulary `stoi`"
      ],
      "metadata": {
        "id": "SxSoQOv91m-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_indices['the']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp7jjb7b2F6Y",
        "outputId": "65118e56-d463-400d-e261-923327f07e61"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "kO2Na33N2N6u"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('vocab-tf.json', 'w') as f:\n",
        "  json.dump(word_indices, f)\n",
        "\n",
        "files.download('vocab-tf.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "agGazncx1ldq",
        "outputId": "bd442a51-d5c8-4532-bb7b-e574d2261d10"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ecb10656-19b7-4442-9bf5-bc2b85ee6d2e\", \"vocab-tf.json\", 1356398)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0-X81blg2_LI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}